# Awesome CV Adversarial Attack List
This repository is a curated list of papers and open source code about competition for CV Adversarial Attack.

## Paper
* Adversarial Examples in Modern Machine Learning: A Review [[Paper]](https://arxiv.org/pdf/1911.05268.pdf)
* Adversarial Attacks and Defenses in Images, Graphs and Text: A Review [[Paper]](https://arxiv.org/pdf/1909.08072.pdf)
* Adversarial Atacks and Defences: A Survey [[Paper]](https://arxiv.org/pdf/1810.00069.pdf)
* Adversarial Examples: Opportunities and Challenges [[Paper]](https://arxiv.org/pdf/1808.04790.pdf)
* Threat of Adversarial Attacks on Deep Learning in Computer Vision: A Survey [[Paper]](https://arxiv.org.pdf/1801.00553.pdf)
* Adversarial Examples: Attacks and Defenses for Deep Learning [[Paper]](https://arxiv.org.pdf/1712.07107.pdf)
* Adversarial Attacks and Defences Competition [[Paper]](https://arxiv.org.pdf/1804.00097.pdf)


## Competion and Solution
* [NIPS 2017: Targeted Adversarial Attack](https://www.kaggle.com/c/nips-2017-targeted-adversarial-attack)  
**dongyp13 : 1th place** [[code]](https://github.com/dongyp13/Targeted-Adversarial-Attack)
[[Boosting Adversarial Attacks with Momentum]](https://arxiv.org/abs/1710.06081)  
rwightman : pytorch-nips2017-attack-example [[code]](https://github.com/rwightman/pytorch-nips2017-attack-example)  
anlthms [[code]](https://github.com/anlthms/nips-2017)   
erko [[code]](https://github.com/erko/nips17-targeted-attack)  
Stanford&Suns [[code]](https://github.com/ftramer/stanford-suns-nips17)  
ysharma1126 [[code]](https://github.com/ysharma1126/nips2017_adversarial_competition)  
EdwardTyantov [[code]](https://github.com/EdwardTyantov/kaggle-nips-adversarial-attacks)  
ckomaki [[code]](https://github.com/ckomaki/kaggle-nips-2017)

* [NIPS 2017: Non-Targeted Adversarial Attack](https://www.kaggle.com/c/nips-2017-non-targeted-adversarial-attack)  
**dongyp13 : 1th place** [[code]](https://github.com/dongyp13/Non-Targeted-Adversarial-Attacks)  
**toshi-k : 5th place** [[code]](https://github.com/toshi-k/kaggle-nips-2017-adversarial-attack)

* [NIPS 2017: DefenseAgainst Adversarial Attack](https://www.kaggle.com/c/nips-2017-defense-against-adversarial-attack)  
**cihangxie : 2th place** [[code]](https://github.com/cihangxie/NIPS2017_adv_challenge_defense)  
lfz [[code]](https://github.com/dongyp13/Non-Targeted-Adversarial-Attacks)  
Roy-YL [[code]](https://github.com/Roy-YL/VAE-Adversarial-Defense)  

* [CAAD2018 ](http://hof.geekpwn.org/caad/zh/index.html)  
ysharma1126 [[Tech Report]](https://arxiv.org/abs/1810.01268)  
FAIR & JHU team [[Tech Report]](https://arxiv.org/pdf/1812.03411.pdf)  
TSAIL team [[Attack Tech Report]](http://hof.geekpwn.org/caad/docs/TSAIL_Attack.pdf)   
TSAIL team [[Defense Tech Report]](http://hof.geekpwn.org/caad/docs/TSAIL_Defense.pdf)  
DLight team [[Tech Report]](http://hof.geekpwn.org/caad/docs/DLight_attack_defence.pdf)  
NorthWest Sec team [[Tech Report]](CAAD_technical_report_team_NWSec_20181019.pdf)    
Teaflow team [[Tech Report]](http://hof.geekpwn.org/caad/docs/TeaflowSummaryEn.pdf)   
RNG team [[Tech Report]](http://hof.geekpwn.org/caad/docs/RNG.pdf)    
Kunlin team [[Tech Report]](http://hof.geekpwn.org/caad/docs/Kunlin_defense.pdf)   
Official source code [[code]](https://github.com/geekpwn/CAAD2018/tree/master/winners)  
jxjrework [[code]](https://github.com/jxjrework/adversarial-dev-factory)  
tianweiy [[code]](https://github.com/tianweiy/CAAD-Solution)  
geekpwn [[code]](https://github.com/geekpwn/CAAD2018)  
0three [[code]](https://github.com/0three/CAAD-2018-Kunlin)

* [MCS 2018. Adversarial Attacks on Black Box Face Recognition](https://competitions.codalab.org/competitions/19090#participate)  
snakers4 [[code]](https://github.com/snakers4/msc-2018-final)
[[Tech Report]](http://baijiahao.baidu.com/s?id=1605052049747008262&wfr=spider&for=pc)

* [IJCAI-19: 阿里巴巴人工智能对抗算法竞赛](https://tianchi.aliyun.com/markets/tianchi/ijcai19_cn)  
**Jowekk : 2th place in the defense track** [[code]](https://github.com/Jowekk/Defense-IJCAI-2019-AAAC)  
**jiangyangzhou : 5th place in the non-targted attack track** [[code]](https://github.com/jiangyangzhou/Non-targeted-Attack-IJCAI2019-ColdRiver)  
**cshanjiewu : 6th place in the targted attack track** [[code]](https://github.com/cshanjiewu/target_attack_IJCAI2019_competition)  
yfreedomliTHU [[code]](https://github.com/yfreedomliTHU/IJCAI2019_AAAC)

* [天池：安全AI挑战者计划第一期-人脸识别对抗](https://tianchi.aliyun.com/competition/entrance/231745/introduction)  
**BruceQFWang 4th place** [[code]](https://github.com/BruceQFWang/TIANCHI_BlackboxAdversial)  
**tabsun 10th place** [[code]](https://github.com/tabsun/FaceAttack)  
**InoriJam 11th place** [[code]](https://github.com/InoriJam/Insightface-Attack)  
SunnyWangGitHub [[code]](https://github.com/SunnyWangGitHub/TianChi_Face_recognition_confrontation)
[[Tech Report]](http://baijiahao.baidu.com/s?id=1605052049747008262&wfr=spider&for=pc)


## Repository
* cleverhans [[Link]](https://github.com/tensorflow/cleverhans)  
* foolbox [[Link]](https://github.com/bethgelab/foolbox/)  
* adversarial-robustness-toolbox (ART) [[Link]](https://github.com/IBM/adversarial-robustness-toolbox)  
* Adversarial-Examples-Reading-List [[Link]](Adversarial-Examples-Reading-List)  
* adversarial-example-pytorch [[Link]](https://github.com/sarathknv/adversarial-examples-pytorch)  
* advertorch [[Link]](https://github.com/BorealisAI/advertorch)  
* EvadeML-Zoo [[Link]](https://github.com/mzweilin/EvadeML-Zoo)


## Tutorials
* [知乎：如何看待机器视觉的“对抗样本”问题，其原理是什么？](https://www.zhihu.com/question/49129585?sort=created)  
* [对抗样本](https://www.zhihu.com/topic/20181666/hot)
* NIPS 2017对抗样本攻防竞赛总结 [[Link]](https://www.leiphone.com/news/201804/WcmoNd6pO4bTQ1yV.html)  
* 产生和防御对抗样本的新方法|分享总结 [[Link]](https://www.leiphone.com/news/201801/eqwoT6Q4KFzXtjyy.html)   
* 清华参赛队攻击组论文 [[Boosting Adversarial Attacks with Momentum]](https://arxiv.org/abs/1710.06081)  
* 清华参赛队防御组论文 [[Defense against Adversarial Attacks Using High-Level Representation Guided Denoiser]](https://arxiv.org/abs/1712.02976) 
* 动量迭代攻击和高层引导去噪：对抗样本攻防的新方法 [[Video]](http://www.mooc.ai/open/course/383)
* AI安全大佬教你如何攻击云端图像分类模型|纯干货 [[Link]](http://www.sohu.com/a/320900665_114877)